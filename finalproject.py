# -*- coding: utf-8 -*-
"""FinalProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZPM5fheDhuBjTF6QxHKedAD0ncC58BUU
"""

import numpy as np
from scipy import signal
import matplotlib.pyplot as plot
import random
import sklearn
import math

#Randomly partitions a set of index values into three subsets:
#training, validation and testing, sets designated gap index values as testing indexes
def partitionNset(N, gap):
  train = np.array([])
  valid = np.array([])
  test = np.array([])
  for i in range(N):
    selector = random.choice([1, 2, 3])
    if selector == 1:
      if not (i in gap[:]):
        train = np.append(train, [int(i)])
      else:
        test = np.append(test, [int(i)])
      
    elif selector == 2:
      valid = np.append(valid, [int(i)])
    elif selector == 3:
      test = np.append(test, [int(i)])
  return train, valid, test

#Used to create the initial model u_0, sets specifically indexed data to 0.
def setToZero(arr, indices):
  newarray = np.copy(arr)
  L = newarray.size
  for i in range(indices.size):
    if indices[i] <= L:
      newarray[int(indices[int(i)])] = 0

  return newarray

#Adds a normally distributed random variable to specifically indexed data 
def randomize(arr, indices, variation):
  newarray = np.copy(arr)
  L = newarray.size
  for i in range(indices.size):
    if indices[i] <= L:
      newarray[int(indices[int(i)])] = newarray[int(indices[int(i)])] + np.random.normal(scale=variation)

  return newarray

# Wrapper function for the lp filter
def filter(sig, freq):
  sos = signal.butter(5, freq, 'lp', fs=1000, output='sos')
  filtered = signal.sosfilt(sos, sig)
  return filtered


  

#Used to reset training data after each filter iteration
def update_train(arr, arr2, indices):
  newarray = arr
  N = newarray.size
  M = arr2.size
  for i in range(indices.size):
    if indices[i] <= N and indices[i] <= M:
      newarray[int(indices[int(i)])] = arr2[int(indices[int(i)])]

  return newarray

#Executes the main model training process until R^2 score minimum is reached or
#number of iterations reaches maximum
def run_process(untrained, true_data, cycles, train_index_values, valid_index_values, nontrain):
  scores = np.array([])
  current_score = 0
  trained = np.copy(untrained)
  frequency = 1
  i = 1
  frequency = 1
  while (i <= cycles) and (current_score < .99) and (frequency < 499):
    frequency = 499/(1 + np.exp(-5*(i - cycles/2)/cycles))
    
    for j in range(5):
      #trained = randomize(trained, nontrain, pow(.6, i*(j+1)))
      trained = filter(trained, frequency)
      current_score = calculate_R2(true_data, trained, valid_index_values)
      scores = np.append(scores, [current_score])
      trained = update_train(trained, true_data, train_index_values)
   
    i = i + 1
    
  return trained, scores

#Calculates the R^2 score on specified index values
def calculate_R2(true_data, predicted, indices):
  if true_data.size == predicted.size:
    true_values = sub_array(true_data, indices)
    pred_values = sub_array(predicted, indices)
    mean = np.mean(true_data)
    mean_array = np.full((1, true_data.size), mean)
    var = math.pow(np.linalg.norm(true_data - mean_array), 2)
    res_sum = math.pow(np.linalg.norm(true_data - predicted), 2)
    return (1 - res_sum/var)

#Used to calculate R^2 score, returns a subarray.
def sub_array(arr, indices):
  sub = np.array([])
  for i in range(indices.size):
    sub = np.append(sub, [arr[int(indices[i])]])
  return sub

 
#Generate data sets:
data_sample_number = 1000
time = np.arange(0, 1, 1/data_sample_number)

#Data set 1, no noise added
data_set1 = np.random.normal(scale=1, size=data_sample_number)
data_set1 = filter(data_set, 10)
gap_data1 = np.array([])

#Data set 2, missing 'gap' data
data_set2 = np.random.normal(scale=2, size=data_sample_number)
data_set2 = filter(data_set, 10)
gap_data2 = np.arange(450, 550, 1)

#Data set 3, noisy signal
data_set3 = np.random.normal(scale=2, size=data_sample_number)
data_set3 = filter(data_set, 10)
data_set3 = data_set + np.random.normal(scale=.02, size=data_sample_number)
gap_data3 = np.array([])

#Set current data set, gap data to data_set i, gap_data i
current_data_set = data_set1
current_gap_data = gap_data1

#Plot data set 
fig, ax = plot.subplots(figsize=(11,6))
ax.scatter(time, current_data_set, s=2)
plot.title("Original data set")
plot.xlabel("predictor variable x")
plot.ylabel("response variable y")
plot.show()

#Partition index set into training, validation, testing subsets. Gap_data indices
#are automatically designated as testing data indices
train_ind, valid_ind, test_ind = partitionNset(current_data_set.size, current_gap_data)

#Combine validation and testing subsets
zero_ind = np.append(valid_ind, test_ind)

#Initialize the model by setting validation and testing indexed entries to 0
untrained_model = setToZero(current_data_set, zero_ind)

#Plot untrained model
fig, ax = plot.subplots(figsize=(11,6))
ax.scatter(time, untrained_model, s=2)
plot.title("Initial model u_0")
plot.xlabel("predictor variable x")
plot.ylabel("response variable u_0(x)")
plot.show()

#Train model for at most 25 cycles (a total of 25*5 = 125 filter iterations)
trained_model, scores = run_process(untrained_model, current_data_set, 25, train_ind, valid_ind, zero_ind)

#Plot trained model
fig, ax = plot.subplots(figsize=(11,6))
ax.scatter(time, trained_model, s=2)
plot.title("Trained model u")
plot.xlabel("predictor variable x")
plot.ylabel("response variable u(x)")
plot.show()

#Plot R^2 scores
fig, ax = plot.subplots(figsize=(11,6))
ax.plot(scores)
plot.title("R^2 score vs iteration")
plot.xlabel("iteration number")
plot.ylabel("R^2 score")
plot.show()

#Plot both original data set with learned model
fig, ax = plot.subplots(figsize=(11,6))
ax.scatter(time, trained_model, s=2, c="red")
ax.scatter(time, current_data_set, s=2)
plot.title("Real data (blue) vs Model (red)")
plot.xlabel("predictor variable x")
plot.ylabel("response variable u(x), y")
plot.show()

#Print final R^2 score
final_score = scores[scores.size - 1]
print("Final score:")
print(final_score)